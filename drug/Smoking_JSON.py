import os
import json
from PIL import Image
from transformers import CLIPProcessor, CLIPModel
import unicodedata

def classify_images_smoking(folder_path, output_json_path):
    """
    ì´ë¯¸ì§€ì—ì„œ í¡ì—° ì¥ë©´ì„ íƒì§€í•˜ê³ , ë¹„í¡ì—° í›„ë³´êµ°ê³¼ ë¹„êµí•˜ì—¬ ìµœì¢… íŒì •ì„ ë‚´ë¦½ë‹ˆë‹¤.
    ê²°ê³¼ëŠ” JSON íŒŒì¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤.
    """

    # ğŸš¬ í¡ì—° ê´€ë ¨ í…ìŠ¤íŠ¸ í›„ë³´êµ° (Positive Class)
    text_candidates_smoking = [
        "A person smoking a cigarette",  
        "A cigarette with visible smoke",  
        "A person exhaling a thick cloud of smoke",  
        "A person vaping with a visible vapor cloud",  
        "A person smoking a cigar",  
        "A cigarette with ashes forming at the tip", 
        "A person flicking ash from a cigarette",  
        "A person holding a cigarette between their fingers",  
        "A person holding a lit cigarette in their mouth",  
    ]

    # ğŸš« ë¹„í¡ì—° ê´€ë ¨ í…ìŠ¤íŠ¸ í›„ë³´êµ° (Negative Class)
    text_candidates_non_smoking = [
        "A person sitting without smoking",  
        "A person drinking coffee without smoking", 
        "A person standing in a non-smoking area",  
        "A person holding a lighter without a cigarette",  
        "A person using a lighter to ignite a candle", 
        "A person holding a lollipop in their mouth",
        "A person holding a white stick(not a cigarette) in their mouth"
    ]

    # CLIP ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
    clip = CLIPModel.from_pretrained("openai/clip-vit-large-patch14")
    processor = CLIPProcessor.from_pretrained("openai/clip-vit-large-patch14")

    def detect_smoking_scene(image_path):
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")

        img = Image.open(image_path)

        # CLIPì„ ì‚¬ìš©í•˜ì—¬ í¡ì—° & ë¹„í¡ì—° í…ìŠ¤íŠ¸ í›„ë³´êµ° ë¹„êµ
        inputs_smoking = processor(text=text_candidates_smoking, images=img, return_tensors="pt", padding=True)
        inputs_non_smoking = processor(text=text_candidates_non_smoking, images=img, return_tensors="pt", padding=True)

        outputs_smoking = clip(**inputs_smoking)
        outputs_non_smoking = clip(**inputs_non_smoking)

        probs_smoking = outputs_smoking.logits_per_image.softmax(dim=1)
        probs_non_smoking = outputs_non_smoking.logits_per_image.softmax(dim=1)

        # ê° ê·¸ë£¹ì—ì„œ ìµœê³  í™•ë¥ ì„ ê°€ì§„ í›„ë³´ ì„ íƒ
        highest_prob_smoking = probs_smoking.max().item()
        highest_prob_non_smoking = probs_non_smoking.max().item()

        # ğŸš¬ í¡ì—° ì¥ë©´ì¸ì§€ ì—¬ë¶€ ê²°ì • (í¡ì—° í™•ë¥ ì´ ë” ë†’ì„ ë•Œë§Œ True)
        is_smoking_scene = highest_prob_smoking > highest_prob_non_smoking

        return {
            "image_name": f"frame_{os.path.splitext(os.path.basename(image_path))[0].split('_')[-1]}.png",
            "highest_prob_smoking": highest_prob_smoking,
            "highest_prob_non_smoking": highest_prob_non_smoking,
            "classification": is_smoking_scene
        }

    folder_path = unicodedata.normalize('NFC', folder_path)
    output_json_path = unicodedata.normalize('NFC', output_json_path)

    if not os.path.exists(folder_path):
        raise FileNotFoundError(f"í´ë” ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {folder_path}")

    image_files = [
        os.path.join(folder_path, file) for file in sorted(os.listdir(folder_path))
        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))
    ]

    results = []
    caption_counts = {}

    for image_path in image_files:
        print(f"ë¶„ì„ ì¤‘: frame_{os.path.splitext(os.path.basename(image_path))[0].split('_')[-1]}.png")
        result = detect_smoking_scene(image_path)
        # classificationì´ Trueì¸ ê²½ìš° í¡ì—° í›„ë³´êµ° ì¤‘ ìµœê³  í™•ë¥ ì— í•´ë‹¹í•˜ëŠ” ìº¡ì…˜ ì¶”ì¶œ
        if result["classification"]:
            img = Image.open(image_path)
            inputs_smoking = processor(text=text_candidates_smoking, images=img, return_tensors="pt", padding=True)
            outputs_smoking = clip(**inputs_smoking)
            probs_smoking = outputs_smoking.logits_per_image.softmax(dim=1)
            _, best_idx = probs_smoking.max(dim=1)
            caption = text_candidates_smoking[best_idx.item()]
            result["caption"] = caption
            caption_counts[caption] = caption_counts.get(caption, 0) + 1
        else:
            result["caption"] = "í¡ì—°ì— í•´ë‹¹í•˜ëŠ” ì¥ë©´ ì—†ìŒ"
        results.append(result)

    # ğŸ“Š í†µê³„ ìš”ì•½ ìƒì„±
    total_scenes = len(results)
    smoking_true_count = sum(1 for item in results if item['classification'] is True)
    smoking_false_count = total_scenes - smoking_true_count
    true_rate = round(smoking_true_count / total_scenes, 2) if total_scenes > 0 else 0
    false_rate = round(smoking_false_count / total_scenes, 2) if total_scenes > 0 else 0

    summary_data = {
        "total_scenes": total_scenes,
        "smoking_true": smoking_true_count,
        "smoking_captions": caption_counts, 
        "smoking_false": smoking_false_count,
        "true_rate": true_rate,
        "false_rate": false_rate
    }
    results.append(summary_data)

    # ğŸ“ ê²°ê³¼ JSON íŒŒì¼ë¡œ ì €ì¥ (í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±)
    output_folder = os.path.dirname(output_json_path)
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    # ğŸ“ ê²°ê³¼ JSON íŒŒì¼ë¡œ ì €ì¥
    sorted_results = sorted(results[:-1], key=lambda x: int(x["image_name"].split("_")[-1].split(".")[0]))  # ë§ˆì§€ë§‰ ìš”ì•½ ë°ì´í„° ì œì™¸ í›„ ì •ë ¬
    sorted_results.append(summary_data)  # ë§ˆì§€ë§‰ ìš”ì•½ ë°ì´í„° ë‹¤ì‹œ ì¶”ê°€
    with open(output_json_path, "w", encoding="utf-8") as json_file:
        json.dump(results, json_file, ensure_ascii=False, indent=4)

    print(f"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_json_path}")
    
# folder_path = 'video_data/í¡ì—°_images_output'
# output_json_path = 'smoking_predictions.json'
# classify_images_smoking(folder_path, output_json_path)
