import os
import subprocess
from datetime import timedelta
from openai import OpenAI
import json
from dotenv import load_dotenv
import glob

def open_ai_load():
    load_dotenv()
    openai_api_key = os.getenv('OPENAI_API_KEY')
    client = OpenAI()
    whisper_client = client 
    return whisper_client

def create_dirs(base_path, relative_path):
    base_name = os.path.splitext(relative_path)[0]  
    os.makedirs(f"./result", exist_ok=True)
    result_folder_path = f"./result/{base_name}"
    os.makedirs(result_folder_path, exist_ok=True)
    output_audio_path = result_folder_path + f"/{base_name}_audio_output/{base_name}_audio.mp3"
    output_images_path = result_folder_path + f"/{base_name}_images_output/frame_%03d.png"
    output_text_path = result_folder_path + f"/{base_name}_text_output/{base_name}_text.txt"
    os.makedirs(os.path.dirname(output_audio_path), exist_ok=True)
    os.makedirs(os.path.dirname(output_images_path), exist_ok=True)
    os.makedirs(os.path.dirname(output_text_path), exist_ok=True)
    os.makedirs(result_folder_path+"/result_json", exist_ok=True)
    return output_audio_path, output_images_path, output_text_path

def time_str_to_seconds(time_str):
    """ 'hh:mm:ss' í˜•ì‹ì˜ ë¬¸ìì—´ì„ ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜ """
    try:
        h, m, s = time_str.split(":")
        return int(h) * 3600 + int(m) * 60 + float(s)
    except Exception as e:
        print(f"âŒ ì‹œê°„ ë¬¸ìì—´ ë³€í™˜ ì˜¤ë¥˜: {e}")
        return 0
    
def format_seconds_to_timestr(seconds):
    """ ì´ˆ ë‹¨ìœ„ë¥¼ 'HH:MM:SS' í˜•ì‹ì˜ ë¬¸ìì—´ë¡œ ë³€í™˜ """
    return str(timedelta(seconds=int(seconds))).zfill(8)

def compute_relative_duration(start_time, end_time):
    """ start_timeê³¼ end_timeì´ ì£¼ì–´ì¡Œì„ ë•Œ, ë‘ ì‹œê°„ì˜ ì°¨ì´ë¥¼ 'HH:MM:SS' í˜•ì‹ìœ¼ë¡œ ë°˜í™˜ """
    diff_seconds = time_str_to_seconds(end_time) - time_str_to_seconds(start_time)
    return format_seconds_to_timestr(diff_seconds)

def get_video_duration(input_video_path):
    """ ffmpegë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ìƒ ê¸¸ì´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ """
    try:
        # ffmpeg ì‹¤í–‰ í›„ stderrì—ì„œ Duration ì •ë³´ ì¶”ì¶œ
        result = subprocess.run(
            ["ffmpeg", "-i", input_video_path],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            encoding="utf-8",
            errors="replace"
        )

        if not result.stderr:
            print("âŒ ffmpeg ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: stderrê°€ ì—†ìŠµë‹ˆë‹¤.")
            return 0

        # Durationì´ í¬í•¨ëœ ë¼ì¸ ì°¾ê¸°
        duration_line = next((line for line in result.stderr.split("\n") if "Duration" in line), None)

        if duration_line:
            try:
                print(f"ğŸ” ffmpeg ì¶œë ¥ì—ì„œ ì°¾ì€ Duration ë¼ì¸: {duration_line}")
                duration_str = duration_line.split(",")[0].split("Duration:")[1].strip()
                h, m, s = map(float, duration_str.split(":"))
                video_length = h * 3600 + m * 60 + s
                print(f"ğŸ¬ ì˜ìƒ ê¸¸ì´: {video_length:.2f}ì´ˆ")
                return video_length
            except (ValueError, IndexError) as e:
                print(f"âŒ ì‹œê°„ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                return 0
        else:
            print("âŒ Duration ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return 0

    except Exception as e:
        print(f"âš ï¸ ì˜ˆì™¸ ë°œìƒ: {e}")
        return 0



def extract_images(input_video_path, output_images_path, start_time=None, duration=None):
    total_duration = get_video_duration(input_video_path)
    
    # ë§Œì•½ start_timeê³¼ duration(ì¢…ë£Œ ì‹œê°)ì´ ëª¨ë‘ ì£¼ì–´ì¡Œë‹¤ë©´ ì‹¤ì œ ì¶”ì¶œ ê¸¸ì´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    if start_time and duration:
        rel_duration = compute_relative_duration(start_time, duration)
    elif duration:
        rel_duration = duration
    else:
        rel_duration = None

    # FPS ì„¤ì •: 1ì‹œê°„ ì´ìƒì´ë©´ 10ì´ˆë‹¹ 1ì¥, 1ì‹œê°„ ë¯¸ë§Œì´ë©´ 1ì´ˆë‹¹ 1ì¥
    if rel_duration:
        video_duration = time_str_to_seconds(rel_duration)
    else:
        video_duration = total_duration

    fps = "1" if video_duration < 3600 else "1/10"
    print(f"ğŸ” ì˜ìƒ ê¸¸ì´: {video_duration}ì´ˆ, FPS ì„¤ì •: {fps}")

    command = ["ffmpeg", "-i", input_video_path, "-vf", f"fps={fps}"]
    if start_time:
        command.extend(["-ss", start_time])
    if rel_duration:
        command.extend(["-t", rel_duration])
    command.append(output_images_path)

    return subprocess.run(command)



# ì˜¤ë””ì˜¤ ì¶”ì¶œ (ffmpeg)
def extract_audio_segments(input_video_path, output_audio_base_path, segment_duration=600, start_time=None, duration=None):
    """ FFMPEGë¥¼ ì‚¬ìš©í•´ ì˜¤ë””ì˜¤ë¥¼ segment_duration(ì´ˆ) ë‹¨ìœ„ë¡œ ë‚˜ëˆ  ì €ì¥.
        start_timeê³¼ duration(ì¢…ë£Œ ì‹œê°)ì´ ì£¼ì–´ì§€ë©´ í•´ë‹¹ êµ¬ê°„ë§Œ ì¶”ì¶œ.
    """
    os.makedirs(os.path.dirname(output_audio_base_path), exist_ok=True)
    
    command = ["ffmpeg"]
    if start_time:
        command.extend(["-ss", start_time])
    # duration íŒŒë¼ë¯¸í„°ê°€ ì¢…ë£Œ ì‹œê°ì´ë¼ë©´ ì‹¤ì œ ê¸¸ì´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    if start_time and duration:
        rel_duration = compute_relative_duration(start_time, duration)
        command.extend(["-t", rel_duration])
    elif duration:
        command.extend(["-t", duration])
        
    command.extend([
        "-i", input_video_path,
        "-f", "segment",
        "-segment_time", str(segment_duration),
        "-c:a", "libmp3lame",
        "-b:a", "192k",
        "-ac", "2",  # MP3 ì¸ì½”ë”© ê°•ì œ ì ìš© & ìŠ¤í…Œë ˆì˜¤ ë³€í™˜
        f"{output_audio_base_path}_%03d.mp3"
    ])
    
    return subprocess.run(command)

def transcribe_audio_segments(client, output_audio_base_path, language, start_time=None, segment_duration=600):
    """ ì—¬ëŸ¬ ê°œì˜ ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ Whisperë¡œ ë³€í™˜ (ì‹¤ì œ ì˜ìƒ ì‹œê°„ ê¸°ì¤€).
        start_timeì´ ì£¼ì–´ì§€ë©´ ê° ì„¸ê·¸ë¨¼íŠ¸ì— í•´ë‹¹ offsetì„ ë”í•©ë‹ˆë‹¤.
    """
    audio_files = sorted(glob.glob(f"{output_audio_base_path}_*.mp3"))
    full_transcription = []
    
    start_offset = time_str_to_seconds(start_time) if start_time else 0

    for idx, audio_file in enumerate(audio_files):
        with open(audio_file, "rb") as f:
            print(f"ğŸ™ Whisper ì²˜ë¦¬ ì¤‘: {audio_file}")
            transcription = client.audio.transcriptions.create(
                model="whisper-1", 
                file=f,
                language=language,
                response_format="verbose_json",
                timestamp_granularities=["segment"]
            )
            offset = start_offset + idx * segment_duration
            for segment in transcription.segments:
                segment.start += offset
                segment.end += offset
            full_transcription.append(transcription)
    return full_transcription

def format_time(seconds):
    return str(timedelta(seconds=int(seconds))).zfill(8)

def write_text(output_text_path, results):
    with open(output_text_path, 'w', encoding='utf-8') as f:
        for result in results:
            for segment in result.segments:
                start_time = format_time(segment.start)
                end_time = format_time(segment.end)
                text = segment.text
                f.write(f"[{start_time} - {end_time}]  {text}\n")
                print(f"[{start_time} - {end_time}]  {text}")

def process_video(input_video_path, start_time=None, duration=None, language='ko'):
    client = open_ai_load()
    base_path, relative_path = input_video_path.split("video_data/")

    # íŒŒì¼ í™•ì¥ì í™•ì¸ ë° ë³€í™˜ (.mkv â†’ .mp4)
    base_name, file_extension = os.path.splitext(relative_path)  # í™•ì¥ì ì¶”ì¶œ
    
    if file_extension.lower() == ".mkv":
        converted_video_path = f"video_data/{base_name}.mp4"
        
        # `.mkv`ë¥¼ `.mp4`ë¡œ ë³€í™˜
        command = [
            "ffmpeg", "-i", input_video_path, "-c:v", "copy", "-c:a", "aac", converted_video_path
        ]
        
        if subprocess.run(command).returncode == 0:
            print(f"âœ… {input_video_path} â†’ {converted_video_path} ë³€í™˜ ì™„ë£Œ")
            input_video_path = converted_video_path  # ë³€í™˜ëœ íŒŒì¼ ê²½ë¡œ ì‚¬ìš©
        else:
            print("âŒ MKV ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
            return
    
    # ë””ë ‰í† ë¦¬ ìƒì„± ë° ê²½ë¡œ ë°˜í™˜
    output_audio_base_path, output_images_path, output_text_path = create_dirs(base_path, relative_path)
 
    # ì˜¤ë””ì˜¤ ì¶”ì¶œ (start_timeê³¼ ì¢…ë£Œ ì‹œê°(duration)ì´ ì£¼ì–´ì§€ë©´ í•´ë‹¹ êµ¬ê°„ë§Œ ì¶”ì¶œ)
    if extract_audio_segments(input_video_path, output_audio_base_path, segment_duration=600, start_time=start_time, duration=duration).returncode == 0:
        print("ğŸ”Š ì˜¤ë””ì˜¤ ë¶„í•  ë° ì¶”ì¶œ ì™„ë£Œ")
    else:
        print("âŒ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
        
    # ì´ë¯¸ì§€ ì¶”ì¶œ
    if extract_images(input_video_path, output_images_path, start_time, duration).returncode == 0:
        print("ğŸ“¸ ì´ë¯¸ì§€ ì¶”ì¶œ ì™„ë£Œ")
    else:
        print("âŒ ì´ë¯¸ì§€ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")

    # Whisperë¡œ í…ìŠ¤íŠ¸ ë³€í™˜ (ë¶„í• ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬; start_time ë°˜ì˜)
    results = transcribe_audio_segments(client, output_audio_base_path, language, start_time=start_time, segment_duration=600)
    
    write_text(output_text_path, results)
    print("âœ… í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ")


# importí•œ í›„ í˜¸ì¶œ ì˜ˆì‹œ
# from this_module import process_video
process_video("video_data/íƒ€ì§œ(ì‹ ì˜ì†).mp4",)
#video_data í´ë” ë§Œë“¤ê³  ì˜ìƒë„£ìœ¼ì‹œë©´ë©ë‹ˆë‹¤
