import os
import subprocess
from datetime import timedelta
from openai import OpenAI
import json
from dotenv import load_dotenv
import glob

def open_ai_load():
    load_dotenv()
    openai_api_key = os.getenv('OPENAI_API_KEY')
    client = OpenAI()
    whisper_client = client 
    return whisper_client

def create_dirs(base_path, relative_path):
    base_name = os.path.splitext(relative_path)[0]  
    os.makedirs(f"./result", exist_ok=True)
    result_folder_path = f"./result/{base_name}"
    os.makedirs(result_folder_path, exist_ok=True)
    output_audio_path = result_folder_path + f"/{base_name}_audio_output/{base_name}_audio.mp3"
    output_images_path = result_folder_path + f"/{base_name}_images_output/frame_%03d.png"
    output_text_path = result_folder_path + f"/{base_name}_text_output/{base_name}_text.txt"
    os.makedirs(os.path.dirname(output_audio_path), exist_ok=True)
    os.makedirs(os.path.dirname(output_images_path), exist_ok=True)
    os.makedirs(os.path.dirname(output_text_path), exist_ok=True)
    os.makedirs(result_folder_path+"/result_json", exist_ok=True)
    return output_audio_path, output_images_path, output_text_path

def get_video_duration(input_video_path):
    """ ffmpegë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ìƒ ê¸¸ì´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ """
    try:
        # ffmpeg ì‹¤í–‰ í›„ stderrì—ì„œ Duration ì •ë³´ ì¶”ì¶œ
        result = subprocess.run(
            ["ffmpeg", "-i", input_video_path],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            encoding="utf-8",
            errors="replace"
        )

        if not result.stderr:
            print("âŒ ffmpeg ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: stderrê°€ ì—†ìŠµë‹ˆë‹¤.")
            return 0

        # Durationì´ í¬í•¨ëœ ë¼ì¸ ì°¾ê¸°
        duration_line = next((line for line in result.stderr.split("\n") if "Duration" in line), None)

        if duration_line:
            try:
                print(f"ğŸ” ffmpeg ì¶œë ¥ì—ì„œ ì°¾ì€ Duration ë¼ì¸: {duration_line}")
                duration_str = duration_line.split(",")[0].split("Duration:")[1].strip()
                h, m, s = map(float, duration_str.split(":"))
                video_length = h * 3600 + m * 60 + s
                print(f"ğŸ¬ ì˜ìƒ ê¸¸ì´: {video_length:.2f}ì´ˆ")
                return video_length
            except (ValueError, IndexError) as e:
                print(f"âŒ ì‹œê°„ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                return 0
        else:
            print("âŒ Duration ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return 0

    except Exception as e:
        print(f"âš ï¸ ì˜ˆì™¸ ë°œìƒ: {e}")
        return 0



def extract_images(input_video_path, output_images_path, start_time=None, duration=None):
    # ì „ì²´ ì˜ìƒ ê¸¸ì´ í™•ì¸
    total_duration = get_video_duration(input_video_path)
    
    # ì²˜ë¦¬í•  êµ¬ê°„ì´ íŠ¹ì •ëœ ê²½ìš°, í•´ë‹¹ êµ¬ê°„ë§Œì„ ê¸°ì¤€ìœ¼ë¡œ fps ì„¤ì •
    if start_time or duration:
        video_duration = duration if duration else total_duration - float(start_time or 0)
    else:
        video_duration = total_duration

    # FPS ì„¤ì •: 1ì‹œê°„ ì´ìƒì´ë©´ 10ì´ˆë‹¹ 1ì¥, 1ì‹œê°„ ë¯¸ë§Œì´ë©´ 1ì´ˆë‹¹ 1ì¥
    fps = "1" if video_duration < 3600 else "1/10"

    print(f"ğŸ” ì˜ìƒ ê¸¸ì´: {video_duration}ì´ˆ, FPS ì„¤ì •: {fps}")

    command = ["ffmpeg", "-i", input_video_path, "-vf", f"fps={fps}"]

    if start_time:
        command.extend(["-ss", str(start_time)])
    if duration:
        command.extend(["-t", str(duration)])

    command.append(output_images_path)

    return subprocess.run(command)


# ì˜¤ë””ì˜¤ ì¶”ì¶œ (ffmpeg)
def extract_audio_segments(input_video_path, output_audio_base_path, segment_duration=600):
    """ FFMPEGë¥¼ ì‚¬ìš©í•´ ì˜¤ë””ì˜¤ë¥¼ segment_duration(ì´ˆ) ë‹¨ìœ„ë¡œ ë‚˜ëˆ  ì €ì¥ """
    os.makedirs(os.path.dirname(output_audio_base_path), exist_ok=True)
    
    command = [
        "ffmpeg", "-i", input_video_path,
        "-f", "segment", "-segment_time", str(segment_duration),
        "-c:a", "libmp3lame", "-b:a", "192k", "-ac", "2",  # âœ… MP3 ì¸ì½”ë”© ê°•ì œ ì ìš© & ìŠ¤í…Œë ˆì˜¤ ë³€í™˜
        f"{output_audio_base_path}_%03d.mp3"
    ]
    
    return subprocess.run(command)

def transcribe_audio_segments(client, output_audio_base_path, language):
    """ ì—¬ëŸ¬ ê°œì˜ ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ Whisperë¡œ ë³€í™˜ (ì‹¤ì œ ì˜ìƒ ì‹œê°„ ê¸°ì¤€) """
    audio_files = sorted(glob.glob(f"{output_audio_base_path}_*.mp3"))  # ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë ¬
    full_transcription = []

    for idx, audio_file in enumerate(audio_files):
        with open(audio_file, "rb") as f:
            print(f"ğŸ™ Whisper ì²˜ë¦¬ ì¤‘: {audio_file}")
            transcription = client.audio.transcriptions.create(
                model="whisper-1", 
                file=f,
                language=language,
                response_format="verbose_json",
                timestamp_granularities=["segment"]
            )

            # í˜„ì¬ ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ì‹œì‘ ì˜¤í”„ì…‹ (idx * segment_duration ì´ˆ)
            offset = idx * 600  # 10ë¶„(600ì´ˆ) ë‹¨ìœ„ë¡œ ì˜¤í”„ì…‹ ì¶”ê°€
            for segment in transcription.segments:
                segment.start += offset
                segment.end += offset

            full_transcription.append(transcription)

    return full_transcription

def format_time(seconds):
    return str(timedelta(seconds=int(seconds))).zfill(8)

def write_text(output_text_path, results):
    with open(output_text_path, 'w', encoding='utf-8') as f:
        for result in results:
            for segment in result.segments:
                start_time = format_time(segment.start)
                end_time = format_time(segment.end)
                text = segment.text
                f.write(f"[{start_time} - {end_time}]  {text}\n")
                print(f"[{start_time} - {end_time}]  {text}")

def process_video(input_video_path, start_time=None, duration=None, language='ko'):
    client = open_ai_load()
    base_path, relative_path = input_video_path.split("video_data/")

    # íŒŒì¼ í™•ì¥ì í™•ì¸ ë° ë³€í™˜ (.mkv â†’ .mp4)
    base_name, file_extension = os.path.splitext(relative_path)  # í™•ì¥ì ì¶”ì¶œ
    
    if file_extension.lower() == ".mkv":
        converted_video_path = f"video_data/{base_name}.mp4"
        
        # `.mkv`ë¥¼ `.mp4`ë¡œ ë³€í™˜
        command = [
            "ffmpeg", "-i", input_video_path, "-c:v", "copy", "-c:a", "aac", converted_video_path
        ]
        
        if subprocess.run(command).returncode == 0:
            print(f"âœ… {input_video_path} â†’ {converted_video_path} ë³€í™˜ ì™„ë£Œ")
            input_video_path = converted_video_path  # ë³€í™˜ëœ íŒŒì¼ ê²½ë¡œ ì‚¬ìš©
        else:
            print("âŒ MKV ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
            return
    
    # ë””ë ‰í† ë¦¬ ìƒì„± ë° ê²½ë¡œ ë°˜í™˜
    output_audio_base_path, output_images_path, output_text_path = create_dirs(base_path, relative_path)

    # ì˜¤ë””ì˜¤ ì¶”ì¶œ (ê¸´ ì˜¤ë””ì˜¤ëŠ” ì—¬ëŸ¬ ê°œì˜ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ”)
    if extract_audio_segments(input_video_path, output_audio_base_path, segment_duration=600).returncode == 0:
        print("ğŸ”Š ì˜¤ë””ì˜¤ ë¶„í•  ë° ì¶”ì¶œ ì™„ë£Œ")
    else:
        print("âŒ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")

    # ì´ë¯¸ì§€ ì¶”ì¶œ
    if extract_images(input_video_path, output_images_path, start_time, duration).returncode == 0:
        print("ğŸ“¸ ì´ë¯¸ì§€ ì¶”ì¶œ ì™„ë£Œ")
    else:
        print("âŒ ì´ë¯¸ì§€ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")

    #Whisperë¡œ í…ìŠ¤íŠ¸ ë³€í™˜ (ë¶„í• ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬)
    results = transcribe_audio_segments(client, output_audio_base_path, language=language)
    
    write_text(output_text_path, results)
    print("âœ… í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ")


# importí•œ í›„ í˜¸ì¶œ ì˜ˆì‹œ
# from this_module import process_video
# process_video("video_data/íƒ€ì§œ(ì‹ ì˜ì†).mp4",)
#video_data í´ë” ë§Œë“¤ê³  ì˜ìƒë„£ìœ¼ì‹œë©´ë©ë‹ˆë‹¤
