
import os
import subprocess
from datetime import timedelta
from openai import OpenAI
import json
from dotenv import load_dotenv


	 

# .env íŒŒì¼ ë¡œë“œ
def open_ai_load():
    load_dotenv()

    ### API Key ë¶ˆëŸ¬ì˜¤ê¸°
    openai_api_key = os.getenv('OPENAI_API_KEY')
    # print(openai_api_key)

    ### OpenAi í•¨ìˆ˜ í˜¸ì¶œ
    client = OpenAI()
    whisper_client= client 
    return whisper_client
# ë””ë ‰í† ë¦¬ ìƒì„± í•¨ìˆ˜
def create_dirs(base_path, relative_path):
    base_name = os.path.splitext(relative_path)[0]  # í™•ì¥ì ì œì™¸í•œ íŒŒì¼ ì´ë¦„ë§Œ ê°€ì ¸ì˜´
    os.makedirs(f"./result", exist_ok=True)
    result_folder_path = f"./result/{base_name}"
    os.makedirs(result_folder_path, exist_ok=True)
    output_audio_path = result_folder_path + f"/{base_name}_audio_output" + f"/{base_name}_audio.mp3"
    output_images_path = result_folder_path + f"/{base_name}_images_output" + f"/frame_%03d.png"
    output_text_path = result_folder_path + f"/{base_name}_text_output" + f"/{base_name}_text.txt"

    os.makedirs(os.path.dirname(output_audio_path), exist_ok=True)
    os.makedirs(os.path.dirname(output_images_path), exist_ok=True)
    os.makedirs(os.path.dirname(output_text_path), exist_ok=True)
    os.makedirs(result_folder_path+"/result_json", exist_ok=True)
    return output_audio_path, output_images_path, output_text_path

# ì˜¤ë””ì˜¤ ì¶”ì¶œ (ffmpeg)
def extract_audio_segments(input_video_path, output_audio_base_path, segment_duration=600):
    """ FFMPEGë¥¼ ì‚¬ìš©í•´ ì˜¤ë””ì˜¤ë¥¼ segment_duration(ì´ˆ) ë‹¨ìœ„ë¡œ ë‚˜ëˆ  ì €ì¥ """
    os.makedirs(os.path.dirname(output_audio_base_path), exist_ok=True)
    
    command = [
        "ffmpeg", "-i", input_video_path,
        "-f", "segment", "-segment_time", str(segment_duration),
        "-c:a", "libmp3lame", "-b:a", "192k", "-ac", "2",  # âœ… MP3 ì¸ì½”ë”© ê°•ì œ ì ìš© & ìŠ¤í…Œë ˆì˜¤ ë³€í™˜
        f"{output_audio_base_path}_%03d.mp3"
    ]
    
    return subprocess.run(command)


def extract_images(input_video_path, output_images_path, start_time=None, duration=None):
    command = ["ffmpeg", "-i", input_video_path, "-vf", "fps=1"] #1ì´ˆë‹¹ í•œì¥
    
    # command = ["ffmpeg", "-i", input_video_path, "-vf", "fps=1/10"] #10ì´ˆë‹¹ í•œì¥
    # command = ["ffmpeg", "-i", input_video_path, "-vf", "fps=1/30"] #30ì´ˆë‹¹ í•œì¥
    # command = ["ffmpeg", "-i", input_video_path, "-vf", "fps=1/60"] #1ë¶„ë‹¹ í•œì¥

    
    if start_time:
        command.extend(["-ss", start_time])
    if duration:
        command.extend(["-t", duration])
    
    command.append(output_images_path)
    return subprocess.run(command)

# Whisper í…ìŠ¤íŠ¸ ë³€í™˜
import glob

def transcribe_audio_segments(client, output_audio_base_path, language):
    """ ì—¬ëŸ¬ ê°œì˜ ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ Whisperë¡œ ë³€í™˜ (ì‹¤ì œ ì˜ìƒ ì‹œê°„ ê¸°ì¤€) """
    audio_files = sorted(glob.glob(f"{output_audio_base_path}_*.mp3"))  # ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë ¬
    full_transcription = []

    for idx, audio_file in enumerate(audio_files):
        with open(audio_file, "rb") as f:
            print(f"ğŸ™ Whisper ì²˜ë¦¬ ì¤‘: {audio_file}")
            transcription = client.audio.transcriptions.create(
                model="whisper-1", 
                file=f,
                language=language,
                response_format="verbose_json",
                timestamp_granularities=["segment"]
            )

            # í˜„ì¬ ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ì‹œì‘ ì˜¤í”„ì…‹ (idx * segment_duration ì´ˆ)
            offset = idx * 600  # 10ë¶„(600ì´ˆ) ë‹¨ìœ„ë¡œ ì˜¤í”„ì…‹ ì¶”ê°€
            for segment in transcription.segments:
                segment.start += offset
                segment.end += offset

            full_transcription.append(transcription)

    return full_transcription


# ì‹œê°„ í¬ë§· ë³€í™˜ í•¨ìˆ˜
def format_time(seconds):
    return str(timedelta(seconds=int(seconds))).zfill(8)


# í…ìŠ¤íŠ¸ íŒŒì¼ì— ê¸°ë¡
def write_text(output_text_path, results):
    with open(output_text_path, 'w', encoding='utf-8') as f:
        for result in results:
            for segment in result.segments:
                start_time = format_time(segment.start)
                end_time = format_time(segment.end)
                text = segment.text
                f.write(f"[{start_time} - {end_time}]  {text}\n")
                print(f"[{start_time} - {end_time}]  {text}")
# ë©”ì¸ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
def process_video(input_video_path, start_time=None, duration=None, language='ko'):
    client = open_ai_load()
    base_path, relative_path = input_video_path.split("video_data/")

    # íŒŒì¼ í™•ì¥ì í™•ì¸ ë° ë³€í™˜ (.mkv â†’ .mp4)
    base_name, file_extension = os.path.splitext(relative_path)  # í™•ì¥ì ì¶”ì¶œ
    
    if file_extension.lower() == ".mkv":
        converted_video_path = f"video_data/{base_name}.mp4"
        
        # `.mkv`ë¥¼ `.mp4`ë¡œ ë³€í™˜
        command = [
            "ffmpeg", "-i", input_video_path, "-c:v", "copy", "-c:a", "aac", converted_video_path
        ]
        
        if subprocess.run(command).returncode == 0:
            print(f"âœ… {input_video_path} â†’ {converted_video_path} ë³€í™˜ ì™„ë£Œ")
            input_video_path = converted_video_path  # ë³€í™˜ëœ íŒŒì¼ ê²½ë¡œ ì‚¬ìš©
        else:
            print("âŒ MKV ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
            return
    
    # ë””ë ‰í† ë¦¬ ìƒì„± ë° ê²½ë¡œ ë°˜í™˜
    output_audio_base_path, output_images_path, output_text_path = create_dirs(base_path, relative_path)

    # ì˜¤ë””ì˜¤ ì¶”ì¶œ (ê¸´ ì˜¤ë””ì˜¤ëŠ” ì—¬ëŸ¬ ê°œì˜ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ”)
    if extract_audio_segments(input_video_path, output_audio_base_path, segment_duration=600).returncode == 0:
        print("ğŸ”Š ì˜¤ë””ì˜¤ ë¶„í•  ë° ì¶”ì¶œ ì™„ë£Œ")
    else:
        print("âŒ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")

    # ì´ë¯¸ì§€ ì¶”ì¶œ
    if extract_images(input_video_path, output_images_path, start_time, duration).returncode == 0:
        print("ğŸ“¸ ì´ë¯¸ì§€ ì¶”ì¶œ ì™„ë£Œ")
    else:
        print("âŒ ì´ë¯¸ì§€ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")

    #Whisperë¡œ í…ìŠ¤íŠ¸ ë³€í™˜ (ë¶„í• ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬)
    results = transcribe_audio_segments(client, output_audio_base_path, language=language)
    
    # ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥
    with open(output_text_path, 'w', encoding='utf-8') as f:
        for result in results:
            for segment in result.segments:
                start_time = format_time(segment.start)
                end_time = format_time(segment.end)
                text = segment.text
                f.write(f"[{start_time} - {end_time}]  {text}\n")
                print(f"[{start_time} - {end_time}]  {text}")

    print("âœ… í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ")

# importí•œ í›„ í˜¸ì¶œ ì˜ˆì‹œ
# from this_module import process_video
#process_video("video_data/ë¶ˆí•œë‹¹.mp4",)
#video_data í´ë” ë§Œë“¤ê³  ì˜ìƒë„£ìœ¼ì‹œë©´ë©ë‹ˆë‹¤